{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbcfec04",
   "metadata": {},
   "source": [
    "## Github link https://github.com/Christian-Vinicio/repo-seriestemporales-g4-pd.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2f1bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CARGA DE DATOS\n",
      "================================================================================\n",
      "Registros cargados: 73,153\n",
      "Columnas: ['Codigo_Sucursal', 'Fecha_Venta', 'Codigo_Producto', 'Unidades_Vendidas', 'Total']\n",
      "\n",
      "Primeras filas:\n",
      "   Codigo_Sucursal Fecha_Venta Codigo_Producto  Unidades_Vendidas   Total\n",
      "0               11  2020-01-02         P105400                486  1324.5\n",
      "1               12  2020-01-02         P407780                 80   218.0\n",
      "2                1  2020-01-02         P407780                366  1000.5\n",
      "3                1  2020-01-02         P185447                504   302.4\n",
      "4                6  2020-01-02         P958288               1452  1102.8\n",
      "\n",
      "================================================================================\n",
      "CREACIÓN DE LAGS Y CARACTERÍSTICAS TEMPORALES\n",
      "================================================================================\n",
      "\n",
      "Creando variables lag...\n",
      "Total de columnas ahora: 21\n",
      "\n",
      "================================================================================\n",
      "APLICACIÓN DE INGENIERÍA DE CARACTERÍSTICAS\n",
      "================================================================================\n",
      "\n",
      "Valores nulos introducidos para demostración:\n",
      "temporada           731\n",
      "unidades_lag_1      105\n",
      "total_lag_1         105\n",
      "unidades_lag_7     2184\n",
      "total_lag_7         735\n",
      "unidades_lag_14    1470\n",
      "total_lag_14       1470\n",
      "unidades_lag_30    3150\n",
      "total_lag_30       3150\n",
      "dtype: int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "i. IMPUTACIÓN DE VARIABLES NUMÉRICAS\n",
      "--------------------------------------------------------------------------------\n",
      "  - unidades_lag_1: imputada con mediana\n",
      "  - unidades_lag_7: imputada con mediana\n",
      "  - unidades_lag_14: imputada con mediana\n",
      "  - unidades_lag_30: imputada con mediana\n",
      "  - total_lag_1: imputada con mediana\n",
      "  - total_lag_7: imputada con mediana\n",
      "  - total_lag_14: imputada con mediana\n",
      "  - total_lag_30: imputada con mediana\n",
      "\n",
      "Valores nulos después de imputación numérica: 0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ii. IMPUTACIÓN DE VARIABLES CATEGÓRICAS\n",
      "--------------------------------------------------------------------------------\n",
      "  - temporada: imputada con moda\n",
      "\n",
      "Valores nulos después de imputación categórica: 0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "iii. CODIFICACIÓN DE VARIABLES CATEGÓRICAS\n",
      "--------------------------------------------------------------------------------\n",
      "  - temporada: Label Encoding aplicado\n",
      "    Mapeo: {'Invierno': np.int64(0), 'Otonio': np.int64(1), 'Primavera': np.int64(2), 'Verano': np.int64(3)}\n",
      "  - dia_semana: One-Hot Encoding aplicado (6 variables creadas)\n",
      "  - Codigo_Sucursal: Label Encoding aplicado\n",
      "  - Codigo_Producto: Label Encoding aplicado\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "iv. TRATAMIENTO DE OUTLIERS\n",
      "--------------------------------------------------------------------------------\n",
      "  - Unidades_Vendidas: 7849 outliers detectados y tratados mediante winsorización\n",
      "  - Total: 8673 outliers detectados y tratados mediante winsorización\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "v. TRANSFORMACIÓN DE VARIABLES NUMÉRICAS\n",
      "--------------------------------------------------------------------------------\n",
      "  - Unidades_Vendidas_tratado:\n",
      "    Skewness antes: 1.211\n",
      "    Skewness después de log: -0.282\n",
      "  - Total_tratado:\n",
      "    Skewness antes: 1.186\n",
      "    Skewness después de log: -0.234\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "vi. ESCALADO DE CARACTERÍSTICAS\n",
      "--------------------------------------------------------------------------------\n",
      "  - StandardScaler aplicado a 5 variables\n",
      "  - MinMaxScaler aplicado a 3 variables\n",
      "\n",
      "================================================================================\n",
      "RESUMEN DEL PIPELINE DE INGENIERÍA DE CARACTERÍSTICAS\n",
      "================================================================================\n",
      "\n",
      "PIPELINE DE TRANSFORMACIONES PARA FORECASTING DE VENTAS:\n",
      "\n",
      "1. IMPUTACIÓN NUMÉRICA:\n",
      "   Variables: unidades_lag_1, unidades_lag_7, unidades_lag_14, unidades_lag_30,\n",
      "              total_lag_1, total_lag_7, total_lag_14, total_lag_30\n",
      "   Método: Mediana\n",
      "   Justificación: La mediana es robusta ante outliers que pueden existir en lags\n",
      "\n",
      "2. IMPUTACIÓN CATEGÓRICA:\n",
      "   Variables: temporada\n",
      "   Método: Moda (valor más frecuente)\n",
      "   Justificación: Preserva la distribución original de categorías\n",
      "\n",
      "3. CODIFICACIÓN CATEGÓRICA:\n",
      "   a) Label Encoding:\n",
      "      - temporada → temporada_encoded\n",
      "      - Codigo_Sucursal → sucursal_encoded\n",
      "      - Codigo_Producto → producto_encoded\n",
      "      Justificación: Variables que pueden actuar como exógenas en el modelo\n",
      "   \n",
      "   b) One-Hot Encoding:\n",
      "      - dia_semana → dia_semana_1, dia_semana_2, ..., dia_semana_6\n",
      "      Justificación: No existe relación ordinal entre días de la semana\n",
      "\n",
      "4. TRATAMIENTO DE OUTLIERS:\n",
      "   Variables: Unidades_Vendidas, Total\n",
      "   Método: Winsorización con límites IQR (Q1-1.5*IQR, Q3+1.5*IQR)\n",
      "   Resultado: Unidades_Vendidas_tratado, Total_tratado\n",
      "   Justificación: Mantiene información sin distorsionar distribución\n",
      "\n",
      "5. TRANSFORMACIÓN NUMÉRICA:\n",
      "   Variables: Unidades_Vendidas_tratado, Total_tratado\n",
      "   Método: Transformación logarítmica (log1p)\n",
      "   Resultado: Unidades_Vendidas_tratado_log, Total_tratado_log\n",
      "   Justificación: Reduce asimetría y estabiliza varianza\n",
      "\n",
      "6. ESCALADO:\n",
      "   a) StandardScaler (media=0, std=1):\n",
      "      Variables: unidades_lag_1, unidades_lag_7, unidades_lag_14,\n",
      "                unidades_rolling_7, unidades_rolling_30\n",
      "      Justificación: Normaliza características para modelos sensibles a escala\n",
      "   \n",
      "   b) MinMaxScaler (rango [0,1]):\n",
      "      Variables: mes, dia_mes, dia_semana\n",
      "      Justificación: Variables temporales acotadas naturalmente\n",
      "\n",
      "VARIABLES FINALES PARA MODELADO:\n",
      "- Variables objetivo: Unidades_Vendidas, Total\n",
      "- Variables exógenas: sucursal_encoded, producto_encoded\n",
      "- Variables temporales: anio, mes, dia_semana, trimestre, temporada_encoded\n",
      "- Variables lag: unidades_lag_1, unidades_lag_7, unidades_lag_14, unidades_lag_30\n",
      "- Variables rolling: unidades_rolling_7, unidades_rolling_30\n",
      "- Variables escaladas: sufijo _scaled y _normalized\n",
      "- Variables transformadas: sufijo _log y _tratado\n",
      "\n",
      "CONSIDERACIONES PARA FORECASTING:\n",
      "- Los lags de 1, 7, 14 y 30 días capturan patrones diarios, semanales y mensuales\n",
      "- Las variables de sucursal y producto permiten modelos jerárquicos\n",
      "- El escalado facilita la convergencia en modelos de ML\n",
      "- La transformación log estabiliza varianza en series temporales\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ESTADÍSTICAS FINALES DEL DATASET\n",
      "================================================================================\n",
      "\n",
      "Dimensiones finales: (73153, 42)\n",
      "Columnas creadas: 42\n",
      "\n",
      "Primeras columnas:\n",
      "['Codigo_Sucursal', 'Fecha_Venta', 'Codigo_Producto', 'Unidades_Vendidas', 'Total', 'anio', 'mes', 'dia_semana', 'dia_mes', 'trimestre', 'temporada', 'unidades_lag_1', 'total_lag_1', 'unidades_lag_7', 'total_lag_7', 'unidades_lag_14', 'total_lag_14', 'unidades_lag_30', 'total_lag_30', 'unidades_rolling_7']\n",
      "\n",
      "Muestra del dataset procesado:\n",
      "     Fecha_Venta  Codigo_Sucursal Codigo_Producto  Unidades_Vendidas  \\\n",
      "2788  2020-05-12                1         P041436                 72   \n",
      "2805  2020-05-13                1         P041436                 12   \n",
      "2937  2020-05-20                1         P041436                  6   \n",
      "2993  2020-05-22                1         P041436                 72   \n",
      "3124  2020-05-28                1         P041436                144   \n",
      "3313  2020-06-05                1         P041436                 72   \n",
      "3333  2020-06-06                1         P041436                216   \n",
      "3851  2020-06-22                1         P041436                  6   \n",
      "4266  2020-07-07                1         P041436                 72   \n",
      "4448  2020-07-13                1         P041436                144   \n",
      "\n",
      "      unidades_lag_7  temporada_encoded  Unidades_Vendidas_tratado_log  \n",
      "2788            96.0                  2                       4.290459  \n",
      "2805            96.0                  2                       2.564949  \n",
      "2937            96.0                  2                       1.945910  \n",
      "2993            96.0                  2                       4.290459  \n",
      "3124            96.0                  2                       4.976734  \n",
      "3313            96.0                  3                       4.290459  \n",
      "3333            96.0                  3                       5.379897  \n",
      "3851            72.0                  3                       1.945910  \n",
      "4266            12.0                  3                       4.290459  \n",
      "4448             6.0                  3                       4.976734  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================================================================================\n",
    "# 1. CARGA Y PREPARACIÓN DEL DATASET\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CARGA DE DATOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cargar el dataset \n",
    "df = pd.read_csv(\"../data/raw/ventas.csv\")\n",
    "\n",
    "# Convertir fecha a datetime\n",
    "df['Fecha_Venta'] = pd.to_datetime(df['Fecha_Venta'], format='%d/%m/%Y')\n",
    "\n",
    "print(f\"Registros cargados: {len(df):,}\")\n",
    "print(f\"Columnas: {list(df.columns)}\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "print(df.head())\n",
    "\n",
    "# ==================================================================================\n",
    "# 2. CREACIÓN DE VARIABLES LAG Y CARACTERÍSTICAS TEMPORALES\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREACIÓN DE LAGS Y CARACTERÍSTICAS TEMPORALES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ordenar por sucursal, producto y fecha\n",
    "df = df.sort_values(['Codigo_Sucursal', 'Codigo_Producto', 'Fecha_Venta'])\n",
    "\n",
    "# Crear características temporales\n",
    "df['anio'] = df['Fecha_Venta'].dt.year\n",
    "df['mes'] = df['Fecha_Venta'].dt.month\n",
    "df['dia_semana'] = df['Fecha_Venta'].dt.dayofweek\n",
    "df['dia_mes'] = df['Fecha_Venta'].dt.day\n",
    "df['trimestre'] = df['Fecha_Venta'].dt.quarter\n",
    "\n",
    "# Crear variable categórica de temporada\n",
    "def asignar_temporada(mes):\n",
    "    if mes in [12, 1, 2]:\n",
    "        return 'Invierno'\n",
    "    elif mes in [3, 4, 5]:\n",
    "        return 'Primavera'\n",
    "    elif mes in [6, 7, 8]:\n",
    "        return 'Verano'\n",
    "    else:\n",
    "        return 'Otonio'\n",
    "\n",
    "df['temporada'] = df['mes'].apply(asignar_temporada)\n",
    "\n",
    "# Crear lags de ventas (1, 7, 14, 30 días)\n",
    "# Los lags más útiles para forecasting son 1, 7, 14 y 30 días\n",
    "print(\"\\nCreando variables lag...\")\n",
    "for lag in [1, 7, 14, 30]:\n",
    "    df[f'unidades_lag_{lag}'] = df.groupby(['Codigo_Sucursal', 'Codigo_Producto'])['Unidades_Vendidas'].shift(lag)\n",
    "    df[f'total_lag_{lag}'] = df.groupby(['Codigo_Sucursal', 'Codigo_Producto'])['Total'].shift(lag)\n",
    "\n",
    "# Rolling means (promedio móvil)\n",
    "df['unidades_rolling_7'] = df.groupby(['Codigo_Sucursal', 'Codigo_Producto'])['Unidades_Vendidas'].transform(\n",
    "    lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    ")\n",
    "df['unidades_rolling_30'] = df.groupby(['Codigo_Sucursal', 'Codigo_Producto'])['Unidades_Vendidas'].transform(\n",
    "    lambda x: x.rolling(window=30, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "print(f\"Total de columnas ahora: {len(df.columns)}\")\n",
    "\n",
    "# ==================================================================================\n",
    "# 3. INGENIERÍA DE CARACTERÍSTICAS\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APLICACIÓN DE INGENIERÍA DE CARACTERÍSTICAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Eliminar valores aleatorios para demostrar imputación\n",
    "indices_nulos_num = np.random.choice(df.index, size=int(0.02 * len(df)), replace=False)\n",
    "df.loc[indices_nulos_num, 'unidades_lag_7'] = np.nan\n",
    "\n",
    "indices_nulos_cat = np.random.choice(df.index, size=int(0.01 * len(df)), replace=False)\n",
    "df.loc[indices_nulos_cat, 'temporada'] = np.nan\n",
    "\n",
    "print(f\"\\nValores nulos introducidos para demostración:\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "\n",
    "# ==================================================================================\n",
    "# i. IMPUTACIÓN DE VARIABLES NUMÉRICAS\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"i. IMPUTACIÓN DE VARIABLES NUMÉRICAS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Criterio: Usar mediana para variables con lags debido a posibles outliers\n",
    "columnas_numericas_imputar = ['unidades_lag_1', 'unidades_lag_7', 'unidades_lag_14', \n",
    "                               'unidades_lag_30', 'total_lag_1', 'total_lag_7', \n",
    "                               'total_lag_14', 'total_lag_30']\n",
    "\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "\n",
    "for col in columnas_numericas_imputar:\n",
    "    if col in df.columns and df[col].isnull().sum() > 0:\n",
    "        df[col] = imputer_num.fit_transform(df[[col]])\n",
    "        print(f\"  - {col}: imputada con mediana\")\n",
    "\n",
    "print(f\"\\nValores nulos después de imputación numérica: {df[columnas_numericas_imputar].isnull().sum().sum()}\")\n",
    "\n",
    "# ==================================================================================\n",
    "# ii. IMPUTACIÓN DE VARIABLES CATEGÓRICAS\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ii. IMPUTACIÓN DE VARIABLES CATEGÓRICAS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Criterio: Usar moda para variables categóricas\n",
    "columnas_categoricas_imputar = ['temporada']\n",
    "\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "for col in columnas_categoricas_imputar:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col] = imputer_cat.fit_transform(df[[col]]).ravel()\n",
    "        print(f\"  - {col}: imputada con moda\")\n",
    "\n",
    "print(f\"\\nValores nulos después de imputación categórica: {df[columnas_categoricas_imputar].isnull().sum().sum()}\")\n",
    "\n",
    "# ==================================================================================\n",
    "# iii. CODIFICACIÓN DE VARIABLES CATEGÓRICAS\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"iii. CODIFICACIÓN DE VARIABLES CATEGÓRICAS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Criterio: Label Encoding para variables ordinales, One-Hot para nominales\n",
    "\n",
    "# Label Encoding para temporada (tiene cierto orden cíclico)\n",
    "le_temporada = LabelEncoder()\n",
    "df['temporada_encoded'] = le_temporada.fit_transform(df['temporada'])\n",
    "print(f\"  - temporada: Label Encoding aplicado\")\n",
    "print(f\"    Mapeo: {dict(zip(le_temporada.classes_, le_temporada.transform(le_temporada.classes_)))}\")\n",
    "\n",
    "# One-Hot Encoding para día de la semana\n",
    "df_dummies = pd.get_dummies(df['dia_semana'], prefix='dia_semana', drop_first=True)\n",
    "df = pd.concat([df, df_dummies], axis=1)\n",
    "print(f\"  - dia_semana: One-Hot Encoding aplicado ({len(df_dummies.columns)} variables creadas)\")\n",
    "\n",
    "# Label Encoding para códigos de sucursal y producto\n",
    "le_sucursal = LabelEncoder()\n",
    "df['sucursal_encoded'] = le_sucursal.fit_transform(df['Codigo_Sucursal'])\n",
    "print(f\"  - Codigo_Sucursal: Label Encoding aplicado\")\n",
    "\n",
    "le_producto = LabelEncoder()\n",
    "df['producto_encoded'] = le_producto.fit_transform(df['Codigo_Producto'])\n",
    "print(f\"  - Codigo_Producto: Label Encoding aplicado\")\n",
    "\n",
    "# ==================================================================================\n",
    "# iv. TRATAMIENTO DE OUTLIERS\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"iv. TRATAMIENTO DE OUTLIERS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Criterio: Utilizar IQR para detectar y limitar outliers\n",
    "def tratar_outliers_iqr(data, columna):\n",
    "    Q1 = data[columna].quantile(0.25)\n",
    "    Q3 = data[columna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers_antes = ((data[columna] < limite_inferior) | (data[columna] > limite_superior)).sum()\n",
    "    \n",
    "    # Winsorización: limitar valores extremos\n",
    "    data[f'{columna}_tratado'] = data[columna].clip(limite_inferior, limite_superior)\n",
    "    \n",
    "    return outliers_antes\n",
    "\n",
    "columnas_outliers = ['Unidades_Vendidas', 'Total']\n",
    "\n",
    "for col in columnas_outliers:\n",
    "    n_outliers = tratar_outliers_iqr(df, col)\n",
    "    print(f\"  - {col}: {n_outliers} outliers detectados y tratados mediante winsorización\")\n",
    "\n",
    "# ==================================================================================\n",
    "# v. TRANSFORMACIÓN DE VARIABLES NUMÉRICAS\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"v. TRANSFORMACIÓN DE VARIABLES NUMÉRICAS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Criterio: Aplicar log para reducir asimetría en variables de ventas\n",
    "columnas_transformar = ['Unidades_Vendidas_tratado', 'Total_tratado']\n",
    "\n",
    "for col in columnas_transformar:\n",
    "    # Agregar constante pequeña para evitar log(0)\n",
    "    df[f'{col}_log'] = np.log1p(df[col])\n",
    "    \n",
    "    # Calcular skewness antes y después\n",
    "    skew_antes = df[col].skew()\n",
    "    skew_despues = df[f'{col}_log'].skew()\n",
    "    print(f\"  - {col}:\")\n",
    "    print(f\"    Skewness antes: {skew_antes:.3f}\")\n",
    "    print(f\"    Skewness después de log: {skew_despues:.3f}\")\n",
    "\n",
    "# ==================================================================================\n",
    "# vi. ESCALADO DE CARACTERÍSTICAS\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"vi. ESCALADO DE CARACTERÍSTICAS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Criterio: StandardScaler para variables con distribución normal\n",
    "# MinMaxScaler para variables acotadas\n",
    "\n",
    "# StandardScaler para lags y rolling means\n",
    "columnas_standard = ['unidades_lag_1', 'unidades_lag_7', 'unidades_lag_14', \n",
    "                     'unidades_rolling_7', 'unidades_rolling_30']\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "df_scaled_std = pd.DataFrame(\n",
    "    scaler_standard.fit_transform(df[columnas_standard]),\n",
    "    columns=[f'{col}_scaled' for col in columnas_standard],\n",
    "    index=df.index\n",
    ")\n",
    "df = pd.concat([df, df_scaled_std], axis=1)\n",
    "print(f\"  - StandardScaler aplicado a {len(columnas_standard)} variables\")\n",
    "\n",
    "# MinMaxScaler para variables temporales\n",
    "columnas_minmax = ['mes', 'dia_mes', 'dia_semana']\n",
    "\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df_scaled_mm = pd.DataFrame(\n",
    "    scaler_minmax.fit_transform(df[columnas_minmax]),\n",
    "    columns=[f'{col}_normalized' for col in columnas_minmax],\n",
    "    index=df.index\n",
    ")\n",
    "df = pd.concat([df, df_scaled_mm], axis=1)\n",
    "print(f\"  - MinMaxScaler aplicado a {len(columnas_minmax)} variables\")\n",
    "\n",
    "# ==================================================================================\n",
    "# 7. RESUMEN DEL PROCESO Y MAPEO DE TRANSFORMACIONES\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN DEL PIPELINE DE INGENIERÍA DE CARACTERÍSTICAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "pipeline_definido = \"\"\"\n",
    "PIPELINE DE TRANSFORMACIONES PARA FORECASTING DE VENTAS:\n",
    "\n",
    "1. IMPUTACIÓN NUMÉRICA:\n",
    "   Variables: unidades_lag_1, unidades_lag_7, unidades_lag_14, unidades_lag_30,\n",
    "              total_lag_1, total_lag_7, total_lag_14, total_lag_30\n",
    "   Método: Mediana\n",
    "   Justificación: La mediana es robusta ante outliers que pueden existir en lags\n",
    "\n",
    "2. IMPUTACIÓN CATEGÓRICA:\n",
    "   Variables: temporada\n",
    "   Método: Moda (valor más frecuente)\n",
    "   Justificación: Preserva la distribución original de categorías\n",
    "\n",
    "3. CODIFICACIÓN CATEGÓRICA:\n",
    "   a) Label Encoding:\n",
    "      - temporada → temporada_encoded\n",
    "      - Codigo_Sucursal → sucursal_encoded\n",
    "      - Codigo_Producto → producto_encoded\n",
    "      Justificación: Variables que pueden actuar como exógenas en el modelo\n",
    "   \n",
    "   b) One-Hot Encoding:\n",
    "      - dia_semana → dia_semana_1, dia_semana_2, ..., dia_semana_6\n",
    "      Justificación: No existe relación ordinal entre días de la semana\n",
    "\n",
    "4. TRATAMIENTO DE OUTLIERS:\n",
    "   Variables: Unidades_Vendidas, Total\n",
    "   Método: Winsorización con límites IQR (Q1-1.5*IQR, Q3+1.5*IQR)\n",
    "   Resultado: Unidades_Vendidas_tratado, Total_tratado\n",
    "   Justificación: Mantiene información sin distorsionar distribución\n",
    "\n",
    "5. TRANSFORMACIÓN NUMÉRICA:\n",
    "   Variables: Unidades_Vendidas_tratado, Total_tratado\n",
    "   Método: Transformación logarítmica (log1p)\n",
    "   Resultado: Unidades_Vendidas_tratado_log, Total_tratado_log\n",
    "   Justificación: Reduce asimetría y estabiliza varianza\n",
    "\n",
    "6. ESCALADO:\n",
    "   a) StandardScaler (media=0, std=1):\n",
    "      Variables: unidades_lag_1, unidades_lag_7, unidades_lag_14,\n",
    "                unidades_rolling_7, unidades_rolling_30\n",
    "      Justificación: Normaliza características para modelos sensibles a escala\n",
    "   \n",
    "   b) MinMaxScaler (rango [0,1]):\n",
    "      Variables: mes, dia_mes, dia_semana\n",
    "      Justificación: Variables temporales acotadas naturalmente\n",
    "\n",
    "VARIABLES FINALES PARA MODELADO:\n",
    "- Variables objetivo: Unidades_Vendidas, Total\n",
    "- Variables exógenas: sucursal_encoded, producto_encoded\n",
    "- Variables temporales: anio, mes, dia_semana, trimestre, temporada_encoded\n",
    "- Variables lag: unidades_lag_1, unidades_lag_7, unidades_lag_14, unidades_lag_30\n",
    "- Variables rolling: unidades_rolling_7, unidades_rolling_30\n",
    "- Variables escaladas: sufijo _scaled y _normalized\n",
    "- Variables transformadas: sufijo _log y _tratado\n",
    "\n",
    "CONSIDERACIONES PARA FORECASTING:\n",
    "- Los lags de 1, 7, 14 y 30 días capturan patrones diarios, semanales y mensuales\n",
    "- Las variables de sucursal y producto permiten modelos jerárquicos\n",
    "- El escalado facilita la convergencia en modelos de ML\n",
    "- La transformación log estabiliza varianza en series temporales\n",
    "\"\"\"\n",
    "\n",
    "print(pipeline_definido)\n",
    "\n",
    "# Guardar resumen estadístico\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ESTADÍSTICAS FINALES DEL DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDimensiones finales: {df.shape}\")\n",
    "print(f\"Columnas creadas: {len(df.columns)}\")\n",
    "print(f\"\\nPrimeras columnas:\")\n",
    "print(df.columns.tolist()[:20])\n",
    "\n",
    "\n",
    "\n",
    "# Mostrar muestra del dataset final\n",
    "print(\"\\nMuestra del dataset procesado:\")\n",
    "print(df[['Fecha_Venta', 'Codigo_Sucursal', 'Codigo_Producto', \n",
    "          'Unidades_Vendidas', 'unidades_lag_7', 'temporada_encoded',\n",
    "          'Unidades_Vendidas_tratado_log']].head(10))\n",
    "\n",
    "# uardar dataset procesado\n",
    "df.to_csv('../data/processed/dataset_procesado.csv', index=False)\n",
    "# print(\"\\nDataset guardado como 'dataset_procesado.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_papd_proyecto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
