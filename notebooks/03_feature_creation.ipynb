{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e5d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREACIÓN DEL PIPELINE DE INGENIERÍA DE CARACTERÍSTICAS\n",
      "================================================================================\n",
      "\n",
      "Pipeline de preprocesamiento creado exitosamente\n",
      "Pasos del pipeline: 6\n",
      "\n",
      "================================================================================\n",
      "CARGANDO DATOS PARA AJUSTAR EL PIPELINE\n",
      "================================================================================\n",
      "Datos cargados: 73,153 registros\n",
      "\n",
      "Pipeline ajustado exitosamente\n",
      "\n",
      "================================================================================\n",
      "PIPELINE GUARDADO\n",
      "================================================================================\n",
      "Ubicación: models\n",
      "\n",
      "El pipeline está listo para ser usado en entrenamiento e inferencia\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CREACIÓN DEL PIPELINE DE INGENIERÍA DE CARACTERÍSTICAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==================================================================================\n",
    "# CLASE MAPPER PERSONALIZADA\n",
    "# ==================================================================================\n",
    "\n",
    "class Mapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables, mappings):\n",
    "        self.variables = variables\n",
    "        self.mappings = mappings\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for variable in self.variables:\n",
    "            X[variable] = X[variable].map(self.mappings).fillna(0)\n",
    "        return X\n",
    "\n",
    "# ==================================================================================\n",
    "# TRANSFORMADOR PARA CREAR LAGS\n",
    "# ==================================================================================\n",
    "\n",
    "class LagCreator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lags=[1, 7, 14, 30]):\n",
    "        self.lags = lags\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X = X.sort_values(['Codigo_Sucursal', 'Codigo_Producto', 'Fecha_Venta'])\n",
    "        \n",
    "        # Solo crear lags de Unidades_Vendidas (NO de Total)\n",
    "        for lag in self.lags:\n",
    "            X[f'unidades_lag_{lag}'] = X.groupby(['Codigo_Sucursal', 'Codigo_Producto'])['Unidades_Vendidas'].shift(lag)\n",
    "        \n",
    "        X['unidades_rolling_7'] = X.groupby(['Codigo_Sucursal', 'Codigo_Producto'])['Unidades_Vendidas'].transform(\n",
    "            lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    "        )\n",
    "        X['unidades_rolling_30'] = X.groupby(['Codigo_Sucursal', 'Codigo_Producto'])['Unidades_Vendidas'].transform(\n",
    "            lambda x: x.rolling(window=30, min_periods=1).mean()\n",
    "        )\n",
    "        \n",
    "        return X\n",
    "\n",
    "# ==================================================================================\n",
    "# TRANSFORMADOR PARA CARACTERÍSTICAS TEMPORALES\n",
    "# ==================================================================================\n",
    "\n",
    "class TemporalFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['Fecha_Venta'] = pd.to_datetime(X['Fecha_Venta'], format='%d/%m/%Y', errors='coerce')\n",
    "        \n",
    "        X['anio'] = X['Fecha_Venta'].dt.year\n",
    "        X['mes'] = X['Fecha_Venta'].dt.month\n",
    "        X['dia_semana'] = X['Fecha_Venta'].dt.dayofweek\n",
    "        X['dia_mes'] = X['Fecha_Venta'].dt.day\n",
    "        X['trimestre'] = X['Fecha_Venta'].dt.quarter\n",
    "        \n",
    "        X['temporada'] = X['mes'].apply(lambda m: \n",
    "            'Invierno' if m in [12, 1, 2] else\n",
    "            'Primavera' if m in [3, 4, 5] else\n",
    "            'Verano' if m in [6, 7, 8] else 'Otonio'\n",
    "        )\n",
    "        \n",
    "        return X\n",
    "\n",
    "# ==================================================================================\n",
    "# TRANSFORMADOR PARA CODIFICACIÓN DE CATEGORÍAS\n",
    "# ==================================================================================\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for col in ['Codigo_Sucursal', 'Codigo_Producto', 'temporada']:\n",
    "            if col in X.columns:\n",
    "                self.encoders[col] = LabelEncoder()\n",
    "                self.encoders[col].fit(X[col].astype(str))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col, encoder in self.encoders.items():\n",
    "            if col in X.columns:\n",
    "                X[f'{col}_encoded'] = encoder.transform(X[col].astype(str))\n",
    "        return X\n",
    "\n",
    "# ==================================================================================\n",
    "# TRANSFORMADOR PARA TRATAMIENTO DE OUTLIERS\n",
    "# ==================================================================================\n",
    "\n",
    "class OutlierTreatment(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.limits = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X.columns:\n",
    "                Q1 = X[col].quantile(0.25)\n",
    "                Q3 = X[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                self.limits[col] = {\n",
    "                    'lower': Q1 - 1.5 * IQR,\n",
    "                    'upper': Q3 + 1.5 * IQR\n",
    "                }\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col, limits in self.limits.items():\n",
    "            if col in X.columns:\n",
    "                X[f'{col}_tratado'] = X[col].clip(limits['lower'], limits['upper'])\n",
    "        return X\n",
    "\n",
    "# ==================================================================================\n",
    "# TRANSFORMADOR PARA TRANSFORMACIONES LOGARÍTMICAS\n",
    "# ==================================================================================\n",
    "\n",
    "class LogTransformation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X.columns:\n",
    "                X[f'{col}_log'] = np.log1p(X[col])\n",
    "        return X\n",
    "\n",
    "# ==================================================================================\n",
    "# TRANSFORMADOR PARA SELECCIÓN DE CARACTERÍSTICAS\n",
    "# ==================================================================================\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        available_features = [f for f in self.features if f in X.columns]\n",
    "        return X[available_features]\n",
    "\n",
    "# ==================================================================================\n",
    "# DEFINICIÓN DE VARIABLES Y CONFIGURACIÓN\n",
    "# ==================================================================================\n",
    "\n",
    "NUMERICAL_VARS_IMPUTE = ['unidades_lag_1', 'unidades_lag_7', 'unidades_lag_14', \n",
    "                         'unidades_lag_30']  # ← Quité total_lag_*\n",
    "\n",
    "OUTLIER_VARS = ['Unidades_Vendidas']  # ← Quité 'Total'\n",
    "\n",
    "LOG_TRANSFORM_VARS = ['Unidades_Vendidas_tratado']  # ← Quité 'Total_tratado'\n",
    "\n",
    "FEATURES_TO_SCALE = ['unidades_lag_1', 'unidades_lag_7', 'unidades_lag_14',\n",
    "                     'unidades_rolling_7', 'unidades_rolling_30', 'mes', \n",
    "                     'dia_mes', 'dia_semana']\n",
    "\n",
    "FEATURES_FOR_MODEL = ['Codigo_Sucursal_encoded', 'Codigo_Producto_encoded',\n",
    "                      'anio', 'mes', 'dia_semana', 'trimestre', 'temporada_encoded',\n",
    "                      'unidades_lag_1', 'unidades_lag_7', 'unidades_lag_14', \n",
    "                      'unidades_lag_30', 'unidades_rolling_7', 'unidades_rolling_30',\n",
    "                      'Unidades_Vendidas_tratado_log']  # ← Quité Total_tratado_log\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# ==================================================================================\n",
    "# CONSTRUCCIÓN DEL PIPELINE \n",
    "# ==================================================================================\n",
    "\n",
    "# Pipeline de imputación solo para columnas numéricas\n",
    "numerical_imputer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# Pipeline de escalado solo para columnas numéricas finales\n",
    "scaler = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# ColumnTransformer que aplica transformaciones específicas a subconjuntos\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num_imputer', numerical_imputer, NUMERICAL_VARS_IMPUTE),\n",
    "    ('scaler', scaler, FEATURES_TO_SCALE)\n",
    "], remainder='passthrough')  # deja pasar las demás columnas\n",
    "\n",
    "# Pipeline principal\n",
    "ventas_preprocessing_pipeline = Pipeline([\n",
    "    ('temporal_features', TemporalFeatures()),\n",
    "    ('lag_creator', LagCreator(lags=[1, 7, 14, 30])),\n",
    "    ('categorical_encoder', CategoricalEncoder()),\n",
    "    ('outlier_treatment', OutlierTreatment(columns=OUTLIER_VARS)),\n",
    "    ('log_transformation', LogTransformation(columns=LOG_TRANSFORM_VARS)),\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "print(\"\\nPipeline de preprocesamiento creado exitosamente\")\n",
    "print(f\"Pasos del pipeline: {len(ventas_preprocessing_pipeline.steps)}\")\n",
    "\n",
    "# ==================================================================================\n",
    "# CARGA Y PREPARACIÓN DE DATOS PARA AJUSTE\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CARGANDO DATOS PARA AJUSTAR EL PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\hsuna\\Desktop\\Proyecto Final Product Development\\proyecto final v2\\repo-seriestemporales-g4-pd\\data\\raw\\ventas.csv')\n",
    "print(f\"Datos cargados: {len(df):,} registros\")\n",
    "\n",
    "# Ajustar el pipeline con los datos\n",
    "X_sample = df.drop(['Total'], axis=1) if 'Total' in df.columns else df\n",
    "ventas_preprocessing_pipeline.fit(X_sample)\n",
    "\n",
    "print(\"\\nPipeline ajustado exitosamente\")\n",
    "\n",
    "# ==================================================================================\n",
    "# EXPORTAR PIPELINE\n",
    "# ==================================================================================\n",
    "\n",
    "pipeline_path = 'models'\n",
    "joblib.dump(ventas_preprocessing_pipeline, pipeline_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE GUARDADO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Ubicación: {pipeline_path}\")\n",
    "print(\"\\nEl pipeline está listo para ser usado en entrenamiento e inferencia\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venr_ugal_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
